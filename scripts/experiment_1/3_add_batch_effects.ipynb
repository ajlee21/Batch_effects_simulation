{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add batch effects\n",
    "\n",
    "Say we are interested in identifying genes that differentiate between disease vs normal states.  However our dataset includes samples from different tissues or time points and there are variations in gene expression that are due to these other conditions and do not have to do with disease state.  These non-relevant variations in the data are called *batch effects*.  \n",
    "\n",
    "We want to model these batch effects.  To do this we will:\n",
    "1. Partition our simulated data into n batches\n",
    "2. For each partition we will randomly shift the expression data.  We randomly generate a binary vector of length=number of genes (*offset vector*).  This vector will serve as the direction that we will shift to.  Then we also have a random scalar that will tell us how big of a step to take in our random direction (*stretch factor*).  We shift our partitioned data by: batch effect partition = partitioned data + stretch factor * offset vector\n",
    "3. Repeat this for each partition\n",
    "4. Append all batch effect partitions together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import umap\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from ggplot import *\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy.random import seed\n",
    "randomState = 123\n",
    "seed(randomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "config_file = \"config_exp_1.txt\"\n",
    "\n",
    "d = {}\n",
    "float_params = [\"learning_rate\", \"kappa\", \"epsilon_std\"]\n",
    "str_params = [\"analysis_name\", \"NN_architecture\"]\n",
    "lst_params = [\"num_batches\"]\n",
    "with open(config_file) as f:\n",
    "    for line in f:\n",
    "        (name, val) = line.split()\n",
    "        if name in float_params:\n",
    "            d[name] = float(val)\n",
    "        elif name in str_params:\n",
    "            d[name] = str(val)\n",
    "        elif name in lst_params:\n",
    "            d[name] = ast.literal_eval(val)\n",
    "        else:\n",
    "            d[name] = int(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "analysis_name = d[\"analysis_name\"]\n",
    "NN_architecture = d[\"NN_architecture\"]\n",
    "num_PCs = d[\"num_PCs\"]\n",
    "num_batches = d[\"num_batches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory already exists: /home/alexandra/Documents/Repos/Batch_effects_simulation/data/batch_simulated/experiment_1\n"
     ]
    }
   ],
   "source": [
    "# Create directories\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(),\"../..\"))\n",
    "\n",
    "new_dir = os.path.join(\n",
    "    base_dir,\n",
    "    \"data\",\n",
    "    \"batch_simulated\")\n",
    "\n",
    "analysis_dir = os.path.join(new_dir, analysis_name)\n",
    "\n",
    "if os.path.exists(analysis_dir):\n",
    "    print('directory already exists: {}'.format(analysis_dir))\n",
    "else:\n",
    "    print('creating new directory: {}'.format(analysis_dir))\n",
    "os.makedirs(analysis_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load arguments\n",
    "simulated_data_file = os.path.join(\n",
    "    base_dir,\n",
    "    \"data\",\n",
    "    \"simulated\",\n",
    "    analysis_name,\n",
    "    \"simulated_data.txt.xz\")\n",
    "\n",
    "umap_model_file = umap_model_file = os.path.join(\n",
    "    base_dir,\n",
    "    \"models\",  \n",
    "    NN_architecture,\n",
    "    \"umap_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in UMAP model\n",
    "infile = open(umap_model_file, 'rb')\n",
    "umap_model = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2490</th>\n",
       "      <th>2491</th>\n",
       "      <th>2492</th>\n",
       "      <th>2493</th>\n",
       "      <th>2494</th>\n",
       "      <th>2495</th>\n",
       "      <th>2496</th>\n",
       "      <th>2497</th>\n",
       "      <th>2498</th>\n",
       "      <th>2499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.474494</td>\n",
       "      <td>0.696870</td>\n",
       "      <td>0.238944</td>\n",
       "      <td>0.267328</td>\n",
       "      <td>0.583896</td>\n",
       "      <td>0.163173</td>\n",
       "      <td>0.235312</td>\n",
       "      <td>0.575820</td>\n",
       "      <td>0.132366</td>\n",
       "      <td>0.400795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757839</td>\n",
       "      <td>0.279478</td>\n",
       "      <td>0.561519</td>\n",
       "      <td>0.491499</td>\n",
       "      <td>0.449728</td>\n",
       "      <td>0.677076</td>\n",
       "      <td>0.124337</td>\n",
       "      <td>0.541154</td>\n",
       "      <td>0.720271</td>\n",
       "      <td>0.433547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.441185</td>\n",
       "      <td>0.550324</td>\n",
       "      <td>0.219221</td>\n",
       "      <td>0.266000</td>\n",
       "      <td>0.590521</td>\n",
       "      <td>0.201786</td>\n",
       "      <td>0.212634</td>\n",
       "      <td>0.536296</td>\n",
       "      <td>0.177473</td>\n",
       "      <td>0.313939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810853</td>\n",
       "      <td>0.320016</td>\n",
       "      <td>0.542352</td>\n",
       "      <td>0.554965</td>\n",
       "      <td>0.502701</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>0.175613</td>\n",
       "      <td>0.481203</td>\n",
       "      <td>0.498466</td>\n",
       "      <td>0.438769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.521074</td>\n",
       "      <td>0.543742</td>\n",
       "      <td>0.336719</td>\n",
       "      <td>0.252867</td>\n",
       "      <td>0.599334</td>\n",
       "      <td>0.291142</td>\n",
       "      <td>0.229665</td>\n",
       "      <td>0.567645</td>\n",
       "      <td>0.187659</td>\n",
       "      <td>0.430471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446711</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>0.392560</td>\n",
       "      <td>0.507871</td>\n",
       "      <td>0.508629</td>\n",
       "      <td>0.474983</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.588248</td>\n",
       "      <td>0.579252</td>\n",
       "      <td>0.413991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.596203</td>\n",
       "      <td>0.551936</td>\n",
       "      <td>0.345861</td>\n",
       "      <td>0.302489</td>\n",
       "      <td>0.531909</td>\n",
       "      <td>0.258675</td>\n",
       "      <td>0.264847</td>\n",
       "      <td>0.422646</td>\n",
       "      <td>0.267940</td>\n",
       "      <td>0.474586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693343</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>0.536226</td>\n",
       "      <td>0.499298</td>\n",
       "      <td>0.492214</td>\n",
       "      <td>0.415613</td>\n",
       "      <td>0.294030</td>\n",
       "      <td>0.536930</td>\n",
       "      <td>0.344359</td>\n",
       "      <td>0.429401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.482794</td>\n",
       "      <td>0.633886</td>\n",
       "      <td>0.303745</td>\n",
       "      <td>0.312830</td>\n",
       "      <td>0.450920</td>\n",
       "      <td>0.218819</td>\n",
       "      <td>0.216378</td>\n",
       "      <td>0.451298</td>\n",
       "      <td>0.235343</td>\n",
       "      <td>0.466791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520269</td>\n",
       "      <td>0.356043</td>\n",
       "      <td>0.461527</td>\n",
       "      <td>0.473496</td>\n",
       "      <td>0.540051</td>\n",
       "      <td>0.382430</td>\n",
       "      <td>0.265336</td>\n",
       "      <td>0.431511</td>\n",
       "      <td>0.512582</td>\n",
       "      <td>0.530147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.426684</td>\n",
       "      <td>0.701658</td>\n",
       "      <td>0.408193</td>\n",
       "      <td>0.342460</td>\n",
       "      <td>0.431087</td>\n",
       "      <td>0.437039</td>\n",
       "      <td>0.298775</td>\n",
       "      <td>0.508043</td>\n",
       "      <td>0.216968</td>\n",
       "      <td>0.542441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577298</td>\n",
       "      <td>0.251121</td>\n",
       "      <td>0.411203</td>\n",
       "      <td>0.367234</td>\n",
       "      <td>0.420593</td>\n",
       "      <td>0.295283</td>\n",
       "      <td>0.319015</td>\n",
       "      <td>0.530860</td>\n",
       "      <td>0.503682</td>\n",
       "      <td>0.435850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.381678</td>\n",
       "      <td>0.589432</td>\n",
       "      <td>0.270064</td>\n",
       "      <td>0.342137</td>\n",
       "      <td>0.629668</td>\n",
       "      <td>0.250987</td>\n",
       "      <td>0.172229</td>\n",
       "      <td>0.401775</td>\n",
       "      <td>0.235665</td>\n",
       "      <td>0.338248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510384</td>\n",
       "      <td>0.377027</td>\n",
       "      <td>0.484328</td>\n",
       "      <td>0.492013</td>\n",
       "      <td>0.541812</td>\n",
       "      <td>0.344019</td>\n",
       "      <td>0.273659</td>\n",
       "      <td>0.545264</td>\n",
       "      <td>0.394876</td>\n",
       "      <td>0.499558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.400522</td>\n",
       "      <td>0.636906</td>\n",
       "      <td>0.228519</td>\n",
       "      <td>0.464320</td>\n",
       "      <td>0.672855</td>\n",
       "      <td>0.236873</td>\n",
       "      <td>0.168115</td>\n",
       "      <td>0.330595</td>\n",
       "      <td>0.260448</td>\n",
       "      <td>0.323219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587457</td>\n",
       "      <td>0.363698</td>\n",
       "      <td>0.611703</td>\n",
       "      <td>0.467752</td>\n",
       "      <td>0.573952</td>\n",
       "      <td>0.355191</td>\n",
       "      <td>0.274361</td>\n",
       "      <td>0.565848</td>\n",
       "      <td>0.402649</td>\n",
       "      <td>0.593904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.501997</td>\n",
       "      <td>0.601793</td>\n",
       "      <td>0.210271</td>\n",
       "      <td>0.388671</td>\n",
       "      <td>0.570547</td>\n",
       "      <td>0.236643</td>\n",
       "      <td>0.168893</td>\n",
       "      <td>0.323124</td>\n",
       "      <td>0.232122</td>\n",
       "      <td>0.416512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779672</td>\n",
       "      <td>0.276626</td>\n",
       "      <td>0.620640</td>\n",
       "      <td>0.533968</td>\n",
       "      <td>0.474002</td>\n",
       "      <td>0.257428</td>\n",
       "      <td>0.229648</td>\n",
       "      <td>0.610038</td>\n",
       "      <td>0.489887</td>\n",
       "      <td>0.498294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.428152</td>\n",
       "      <td>0.623297</td>\n",
       "      <td>0.294565</td>\n",
       "      <td>0.350955</td>\n",
       "      <td>0.502915</td>\n",
       "      <td>0.277763</td>\n",
       "      <td>0.251814</td>\n",
       "      <td>0.494694</td>\n",
       "      <td>0.219805</td>\n",
       "      <td>0.450239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482579</td>\n",
       "      <td>0.388641</td>\n",
       "      <td>0.509143</td>\n",
       "      <td>0.414734</td>\n",
       "      <td>0.456965</td>\n",
       "      <td>0.407720</td>\n",
       "      <td>0.275378</td>\n",
       "      <td>0.559786</td>\n",
       "      <td>0.527550</td>\n",
       "      <td>0.514114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 2500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.474494  0.696870  0.238944  0.267328  0.583896  0.163173  0.235312   \n",
       "1  0.441185  0.550324  0.219221  0.266000  0.590521  0.201786  0.212634   \n",
       "2  0.521074  0.543742  0.336719  0.252867  0.599334  0.291142  0.229665   \n",
       "3  0.596203  0.551936  0.345861  0.302489  0.531909  0.258675  0.264847   \n",
       "4  0.482794  0.633886  0.303745  0.312830  0.450920  0.218819  0.216378   \n",
       "5  0.426684  0.701658  0.408193  0.342460  0.431087  0.437039  0.298775   \n",
       "6  0.381678  0.589432  0.270064  0.342137  0.629668  0.250987  0.172229   \n",
       "7  0.400522  0.636906  0.228519  0.464320  0.672855  0.236873  0.168115   \n",
       "8  0.501997  0.601793  0.210271  0.388671  0.570547  0.236643  0.168893   \n",
       "9  0.428152  0.623297  0.294565  0.350955  0.502915  0.277763  0.251814   \n",
       "\n",
       "          7         8         9    ...         2490      2491      2492  \\\n",
       "0  0.575820  0.132366  0.400795    ...     0.757839  0.279478  0.561519   \n",
       "1  0.536296  0.177473  0.313939    ...     0.810853  0.320016  0.542352   \n",
       "2  0.567645  0.187659  0.430471    ...     0.446711  0.463937  0.392560   \n",
       "3  0.422646  0.267940  0.474586    ...     0.693343  0.364793  0.536226   \n",
       "4  0.451298  0.235343  0.466791    ...     0.520269  0.356043  0.461527   \n",
       "5  0.508043  0.216968  0.542441    ...     0.577298  0.251121  0.411203   \n",
       "6  0.401775  0.235665  0.338248    ...     0.510384  0.377027  0.484328   \n",
       "7  0.330595  0.260448  0.323219    ...     0.587457  0.363698  0.611703   \n",
       "8  0.323124  0.232122  0.416512    ...     0.779672  0.276626  0.620640   \n",
       "9  0.494694  0.219805  0.450239    ...     0.482579  0.388641  0.509143   \n",
       "\n",
       "       2493      2494      2495      2496      2497      2498      2499  \n",
       "0  0.491499  0.449728  0.677076  0.124337  0.541154  0.720271  0.433547  \n",
       "1  0.554965  0.502701  0.587785  0.175613  0.481203  0.498466  0.438769  \n",
       "2  0.507871  0.508629  0.474983  0.246932  0.588248  0.579252  0.413991  \n",
       "3  0.499298  0.492214  0.415613  0.294030  0.536930  0.344359  0.429401  \n",
       "4  0.473496  0.540051  0.382430  0.265336  0.431511  0.512582  0.530147  \n",
       "5  0.367234  0.420593  0.295283  0.319015  0.530860  0.503682  0.435850  \n",
       "6  0.492013  0.541812  0.344019  0.273659  0.545264  0.394876  0.499558  \n",
       "7  0.467752  0.573952  0.355191  0.274361  0.565848  0.402649  0.593904  \n",
       "8  0.533968  0.474002  0.257428  0.229648  0.610038  0.489887  0.498294  \n",
       "9  0.414734  0.456965  0.407720  0.275378  0.559786  0.527550  0.514114  \n",
       "\n",
       "[10 rows x 2500 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "simulated_data = pd.read_table(\n",
    "    simulated_data_file,\n",
    "    header=0, \n",
    "    index_col=0,\n",
    "    compression='xz',\n",
    "    sep='\\t')\n",
    "\n",
    "simulated_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating simulated data with 1 batches..\n",
      "Creating simulated data with 2 batches..\n",
      "Creating simulated data with 5 batches..\n",
      "Creating simulated data with 10 batches..\n",
      "Creating simulated data with 20 batches..\n",
      "Creating simulated data with 50 batches..\n",
      "Creating simulated data with 100 batches..\n",
      "Creating simulated data with 500 batches..\n",
      "Creating simulated data with 1000 batches..\n",
      "Creating simulated data with 2000 batches..\n",
      "Creating simulated data with 3000 batches..\n",
      "Creating simulated data with 6000 batches..\n",
      "CPU times: user 31min 49s, sys: 6min 14s, total: 38min 4s\n",
      "Wall time: 38min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add batch effects\n",
    "num_simulated_samples = simulated_data.shape[0]\n",
    "num_genes = simulated_data.shape[1]\n",
    "subset_genes_to_change = np.random.RandomState(randomState).choice([0, 1], size=(num_genes), p=[3./4, 1./4])\n",
    "    \n",
    "for i in num_batches:\n",
    "    print('Creating simulated data with {} batches..'.format(i))\n",
    "    \n",
    "    batch_file = os.path.join(\n",
    "            base_dir,\n",
    "            \"data\",\n",
    "            \"batch_simulated\",\n",
    "            analysis_name,\n",
    "            \"Batch_\"+str(i)+\".txt.xz\")\n",
    "    \n",
    "    num_samples_per_batch = int(num_simulated_samples/i)\n",
    "    \n",
    "    if i == 1:        \n",
    "        simulated_data.to_csv(batch_file, sep='\\t', compression='xz')\n",
    "        \n",
    "    else:  \n",
    "        batch_data_df = pd.DataFrame()\n",
    "        \n",
    "        simulated_data_draw = simulated_data\n",
    "        for j in range(i):\n",
    "            stretch_factor = np.random.uniform(1.0,1.5)\n",
    "            \n",
    "            # Randomly select samples\n",
    "            batch_df = simulated_data_draw.sample(n=num_samples_per_batch, frac=None, replace=False)\n",
    "            batch_df.columns = batch_df.columns.astype(str)\n",
    "            \n",
    "            # Update df to remove selected samples\n",
    "            sampled_ids = list(batch_df.index)\n",
    "            simulated_data_draw = simulated_data_draw.drop(sampled_ids)\n",
    "\n",
    "            # Add batch effect\n",
    "            subset_genes_to_change_tile = pd.DataFrame(\n",
    "                pd.np.tile(\n",
    "                    subset_genes_to_change,\n",
    "                    (num_samples_per_batch, 1)),\n",
    "                index=batch_df.index,\n",
    "                columns=simulated_data.columns)\n",
    "\n",
    "            offset_vector = pd.DataFrame(subset_genes_to_change_tile*stretch_factor)\n",
    "            offset_vector.columns = offset_vector.columns.astype(str)\n",
    "            batch_df = batch_df + offset_vector\n",
    "            \n",
    "            #batch_df = batch_df*stretch_factor\n",
    "\n",
    "            # if any exceed 1 then set to 1 since gene expression is normalized\n",
    "            batch_df[batch_df>=1.0] = 1.0\n",
    "\n",
    "            # Append batched together\n",
    "            batch_data_df = batch_data_df.append(batch_df)\n",
    "\n",
    "            # Select a new direction (i.e. a new subset of genes to change)\n",
    "            np.random.shuffle(subset_genes_to_change)\n",
    "        \n",
    "        # Save\n",
    "        batch_data_df.to_csv(batch_file, sep='\\t', compression='xz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot batch data using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Plot generated data \\n\\nfor i in num_batches:\\n    batch_data_file = os.path.join(\\n        base_dir,\\n        \"data\",\\n        \"batch_simulated\",\\n        analysis_name,\\n        \"Batch_\"+str(i)+\".txt\")\\n    \\n    batch_data = pd.read_table(\\n        batch_data_file,\\n        header=0,\\n        sep=\\'\\t\\',\\n        index_col=0)\\n    \\n    # UMAP embedding of decoded batch data\\n    batch_data_UMAPencoded = umap_model.transform(batch_data)\\n    batch_data_UMAPencoded_df = pd.DataFrame(data=batch_data_UMAPencoded,\\n                                             index=batch_data.index,\\n                                             columns=[\\'1\\',\\'2\\'])\\n    \\n        \\n    g = ggplot(aes(x=\\'1\\',y=\\'2\\'), data=batch_data_UMAPencoded_df) +                 geom_point(alpha=0.5) +                 scale_color_brewer(type=\\'qual\\', palette=\\'Set2\\') +                 ggtitle(\"{} Batches\".format(i))\\n    \\n    print(g)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Plot generated data \n",
    "\n",
    "for i in num_batches:\n",
    "    batch_data_file = os.path.join(\n",
    "        base_dir,\n",
    "        \"data\",\n",
    "        \"batch_simulated\",\n",
    "        analysis_name,\n",
    "        \"Batch_\"+str(i)+\".txt\")\n",
    "    \n",
    "    batch_data = pd.read_table(\n",
    "        batch_data_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "    \n",
    "    # UMAP embedding of decoded batch data\n",
    "    batch_data_UMAPencoded = umap_model.transform(batch_data)\n",
    "    batch_data_UMAPencoded_df = pd.DataFrame(data=batch_data_UMAPencoded,\n",
    "                                             index=batch_data.index,\n",
    "                                             columns=['1','2'])\n",
    "    \n",
    "        \n",
    "    g = ggplot(aes(x='1',y='2'), data=batch_data_UMAPencoded_df) + \\\n",
    "                geom_point(alpha=0.5) + \\\n",
    "                scale_color_brewer(type='qual', palette='Set2') + \\\n",
    "                ggtitle(\"{} Batches\".format(i))\n",
    "    \n",
    "    print(g)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot batch data using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Plot generated data \\n\\nfor i in num_batches:\\n    batch_data_file = os.path.join(\\n        base_dir,\\n        \"data\",\\n        \"batch_simulated\",\\n        analysis_name,\\n        \"Batch_\"+str(i)+\".txt\")\\n    \\n    batch_data = pd.read_table(\\n        batch_data_file,\\n        header=0,\\n        sep=\\'\\t\\',\\n        index_col=0)\\n    \\n    # PCA projection    \\n    pca = PCA(n_components=num_PCs)\\n    batch_data_PCAencoded = pca.fit_transform(batch_data)\\n    \\n    # Encode data using PCA model    \\n    batch_data_PCAencoded_df = pd.DataFrame(batch_data_PCAencoded,\\n                                         index=batch_data.index\\n                                         )\\n    \\n    g = sns.pairplot(batch_data_PCAencoded_df)\\n    g.fig.suptitle(\"Batch {}\".format(i))\\n       \\n    # Select pairwise PC\\'s to plot\\n    pc1 = 0\\n    pc2 = 2\\n    \\n    # Encode data using PCA model    \\n    batch_data_PCAencoded_df = pd.DataFrame(batch_data_PCAencoded[:,[pc1,pc2]],\\n                                         index=batch_data.index,\\n                                         columns=[\\'PC {}\\'.format(pc1), \\'PC {}\\'.format(pc2)])\\n    \\n    g = ggplot(aes(x=\\'PC {}\\'.format(pc1),y=\\'PC {}\\'.format(pc2)), data=batch_data_PCAencoded_df)  +                 geom_point(alpha=0.5) +                 scale_color_brewer(type=\\'qual\\', palette=\\'Set2\\') +                 ggtitle(\"{} Batches\".format(i))\\n    print(g)\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Plot generated data \n",
    "\n",
    "for i in num_batches:\n",
    "    batch_data_file = os.path.join(\n",
    "        base_dir,\n",
    "        \"data\",\n",
    "        \"batch_simulated\",\n",
    "        analysis_name,\n",
    "        \"Batch_\"+str(i)+\".txt\")\n",
    "    \n",
    "    batch_data = pd.read_table(\n",
    "        batch_data_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "    \n",
    "    # PCA projection    \n",
    "    pca = PCA(n_components=num_PCs)\n",
    "    batch_data_PCAencoded = pca.fit_transform(batch_data)\n",
    "    \n",
    "    # Encode data using PCA model    \n",
    "    batch_data_PCAencoded_df = pd.DataFrame(batch_data_PCAencoded,\n",
    "                                         index=batch_data.index\n",
    "                                         )\n",
    "    \n",
    "    g = sns.pairplot(batch_data_PCAencoded_df)\n",
    "    g.fig.suptitle(\"Batch {}\".format(i))\n",
    "       \n",
    "    # Select pairwise PC's to plot\n",
    "    pc1 = 0\n",
    "    pc2 = 2\n",
    "    \n",
    "    # Encode data using PCA model    \n",
    "    batch_data_PCAencoded_df = pd.DataFrame(batch_data_PCAencoded[:,[pc1,pc2]],\n",
    "                                         index=batch_data.index,\n",
    "                                         columns=['PC {}'.format(pc1), 'PC {}'.format(pc2)])\n",
    "    \n",
    "    g = ggplot(aes(x='PC {}'.format(pc1),y='PC {}'.format(pc2)), data=batch_data_PCAencoded_df)  + \\\n",
    "                geom_point(alpha=0.5) + \\\n",
    "                scale_color_brewer(type='qual', palette='Set2') + \\\n",
    "                ggtitle(\"{} Batches\".format(i))\n",
    "    print(g)\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:batch_effects]",
   "language": "python",
   "name": "conda-env-batch_effects-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
