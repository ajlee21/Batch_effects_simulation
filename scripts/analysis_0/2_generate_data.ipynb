{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data and calculate similarity\n",
    "\n",
    "The goal of this notebook is to determine how much of the structure in the original dataset (single experiment) is retained after adding some number of experiments.\n",
    "\n",
    "The approach is to,\n",
    "1. Generates simulated data by sampling from a trained VAE model.  Simulate ```num_simulated_samples```\n",
    "2. Add number of experiments in ```lst_num_experiments```\n",
    "3. Calculate the similarity between the dataset with a single experiment and the dataset with some number of experiments added.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "from plotnine import ggplot, ggtitle, xlab, ylab, geom_point, geom_line, aes, ggsave\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from functions import generate_data\n",
    "from functions import similarity_metric\n",
    "\n",
    "from numpy.random import seed\n",
    "randomState = 123\n",
    "seed(randomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User parameters\n",
    "NN_architecture = 'NN_2500_30'\n",
    "analysis_name = 'analysis_0'\n",
    "num_simulated_samples = 6000\n",
    "lst_num_experiments = [1,2,5,10,20,50,100,500,1000,2000,3000,6000]\n",
    "use_pca = True\n",
    "num_PCs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(),\"../..\"))    # base dir on repo\n",
    "local_dir = \"/home/alexandra/Documents/\"                         # base dir on local machine for data storage\n",
    "                                                                 # Save doesn't recognize ~\n",
    "\n",
    "normalized_data_file = os.path.join(\n",
    "    base_dir,\n",
    "    \"data\",\n",
    "    \"input\",\n",
    "    \"train_set_normalized.pcl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output file\n",
    "svcca_file = os.path.join(\n",
    "    local_dir,\n",
    "    \"Data\",\n",
    "    \"Batch_effects\",\n",
    "    \"output\",\n",
    "    \"svcca.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: \n",
      " /home/alexandra/Documents/Data/Batch_effects/simulated/analysis_0\n",
      "\n",
      "\n",
      "Normalized gene expression data contains 950 samples and 5549 genes\n",
      "Return: simulated gene expression data containing 6000 samples and 5549 genes\n"
     ]
    }
   ],
   "source": [
    "# Generate simulated data\n",
    "generate_data.simulate_data(normalized_data_file,\n",
    "                            NN_architecture,\n",
    "                            analysis_name,\n",
    "                            num_simulated_samples\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated data file \n",
    "simulated_data_file = os.path.join(\n",
    "    local_dir,\n",
    "    \"Data\",\n",
    "    \"Batch_effects\",\n",
    "    \"simulated\",\n",
    "    analysis_name,\n",
    "    \"simulated_data.txt.xz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate permuted version of simulated data (negative control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permute simulated data to be used as a negative control\n",
    "generate_data.permute_data(simulated_data_file,\n",
    "                          local_dir,\n",
    "                          analysis_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permuted simulated data file \n",
    "permuted_simulated_data_file = os.path.join(\n",
    "    local_dir,\n",
    "    \"Data\",\n",
    "    \"Batch_effects\",\n",
    "    \"simulated\",\n",
    "    analysis_name,\n",
    "    \"permuted_simulated_data.txt.xz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add number of experiments to simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: \n",
      " /home/alexandra/Documents/Data/Batch_effects/experiment_simulated/analysis_0\n",
      "\n",
      "\n",
      "Creating simulated data with 1 experiments..\n",
      "Creating simulated data with 2 experiments..\n",
      "Creating simulated data with 5 experiments..\n",
      "Creating simulated data with 10 experiments..\n",
      "Creating simulated data with 20 experiments..\n",
      "Creating simulated data with 50 experiments..\n",
      "Creating simulated data with 100 experiments..\n",
      "Creating simulated data with 500 experiments..\n",
      "Creating simulated data with 1000 experiments..\n",
      "Creating simulated data with 2000 experiments..\n",
      "Creating simulated data with 3000 experiments..\n",
      "Creating simulated data with 6000 experiments..\n"
     ]
    }
   ],
   "source": [
    "# Add batch effects\n",
    "generate_data.add_experiments(simulated_data_file,\n",
    "                               lst_num_experiments,\n",
    "                               local_dir,\n",
    "                               analysis_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating SVCCA score for 1 experiment vs 1 experiments..\n",
      "Calculating SVCCA score for 1 experiment vs 2 experiments..\n",
      "Calculating SVCCA score for 1 experiment vs 5 experiments..\n",
      "Calculating SVCCA score for 1 experiment vs 10 experiments..\n",
      "Calculating SVCCA score for 1 experiment vs 20 experiments..\n",
      "Calculating SVCCA score for 1 experiment vs 50 experiments..\n",
      "Calculating SVCCA score for 1 experiment vs 100 experiments..\n",
      "Calculating SVCCA score for 1 experiment vs 500 experiments..\n"
     ]
    }
   ],
   "source": [
    "# Calculate similarity\n",
    "batch_scores, permuted_score = similarity_metric.sim_svcca(simulated_data_file,\n",
    "                                                           permuted_simulated_data_file,\n",
    "                                                           'Experiment',\n",
    "                                                           lst_num_experiments,\n",
    "                                                           use_pca,\n",
    "                                                           num_PCs,\n",
    "                                                           local_dir,\n",
    "                                                           analysis_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert similarity scores to pandas dataframe\n",
    "similarity_score_df = pd.DataFrame(data={'score': batch_scores},\n",
    "                                     index=lst_num_experiments,\n",
    "                                    columns=['score'])\n",
    "similarity_score_df.index.name = 'number of experiments'\n",
    "similarity_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "threshold = pd.DataFrame(\n",
    "    pd.np.tile(\n",
    "        permuted_score,\n",
    "        (len(lst_num_experiments), 1)),\n",
    "    index=lst_num_experiments,\n",
    "    columns=['score'])\n",
    "\n",
    "g = ggplot(similarity_score_df, aes(x=lst_num_experiments, y='score')) \\\n",
    "    + geom_line() \\\n",
    "    + geom_line(aes(x=lst_num_experiments, y='score'), threshold, linetype='dashed') \\\n",
    "    + xlab('Number of Experiments') \\\n",
    "    + ylab('Similarity score (SVCCA)') \\\n",
    "    + ggtitle('Similarity across varying numbers of experiments')\n",
    "\n",
    "print(g)\n",
    "ggsave(plot=g, filename=svcca_file, dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:batch_effects]",
   "language": "python",
   "name": "conda-env-batch_effects-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
