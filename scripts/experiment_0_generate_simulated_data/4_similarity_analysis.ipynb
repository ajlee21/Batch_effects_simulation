{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity analysis\n",
    "\n",
    "We want to determine if the different batch simulated data is able to capture the biological signal that is present in the original data:  How much of the real input data is captured in the simulated batch data?\n",
    "\n",
    "In other words, we want to compare the representation of the real input data and the simulated batch data.  We will use **SVCCA** to compare these two representations.\n",
    "\n",
    "Here, we apply Singular Vector Canonical Correlation Analysis [Raghu et al. 2017](https://arxiv.org/pdf/1706.05806.pdf) [(github)](https://github.com/google/svcca) to the UMAP and PCA representations of our batch 1 simulated dataset vs batch n simulated datasets.  The output of the SVCCA analysis is the SVCCA mean similarity score. This single number can be interpreted as a measure of similarity between our original data vs batched dataset.\n",
    "\n",
    "Briefly, SVCCA uses Singular Value Decomposition (SVD) to extract the components explaining 99% of the variation. This is done to remove potential dimensions described by noise. Next, SVCCA performs a Canonical Correlation Analysis (CCA) on the SVD matrices to identify maximum correlations of linear combinations of both input matrices. The algorithm will identify the canonical correlations of highest magnitude across and within algorithms of the same dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandra/anaconda3/envs/batch_effects/lib/python3.5/site-packages/ggplot/utils.py:81: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access Timestamp as pandas.Timestamp\n",
      "  pd.tslib.Timestamp,\n",
      "/home/alexandra/anaconda3/envs/batch_effects/lib/python3.5/site-packages/ggplot/stats/smoothers.py:4: FutureWarning: The pandas.lib module is deprecated and will be removed in a future version. These are private functions and can be accessed from pandas._libs.lib instead\n",
      "  from pandas.lib import Timestamp\n",
      "/home/alexandra/anaconda3/envs/batch_effects/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import umap\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "from ggplot import *\n",
    "from functions import cca_core\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from numpy.random import seed\n",
    "randomState = 123\n",
    "seed(randomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "config_file = os.path.join(\n",
    "    os.path.abspath(os.path.join(os.getcwd(),\"../..\")),\n",
    "    \"data\",\n",
    "    \"metadata\",\n",
    "    \"config_exp_0.txt\")\n",
    "\n",
    "d = {}\n",
    "float_params = [\"learning_rate\", \"kappa\", \"epsilon_std\"]\n",
    "str_params = [\"analysis_name\", \"NN_architecture\"]\n",
    "lst_params = [\"num_batches\"]\n",
    "with open(config_file) as f:\n",
    "    for line in f:\n",
    "        (name, val) = line.split()\n",
    "        if name in float_params:\n",
    "            d[name] = float(val)\n",
    "        elif name in str_params:\n",
    "            d[name] = str(val)\n",
    "        elif name in lst_params:\n",
    "            d[name] = ast.literal_eval(val)\n",
    "        else:\n",
    "            d[name] = int(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "analysis_name = d[\"analysis_name\"]\n",
    "NN_architecture = d[\"NN_architecture\"]\n",
    "num_PCs = d[\"num_PCs\"]\n",
    "num_batches = d[\"num_batches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(),\"../..\"))\n",
    "\n",
    "simulated_data_file = os.path.join(\n",
    "    base_dir,\n",
    "    \"data\",\n",
    "    \"simulated\",\n",
    "    analysis_name,\n",
    "    \"simulated_data.txt\")\n",
    "\n",
    "batch_dir = os.path.join(\n",
    "    base_dir,\n",
    "    \"data\",\n",
    "    \"batch_simulated\",\n",
    "    analysis_name)\n",
    "\n",
    "umap_model_file = umap_model_file = os.path.join(\n",
    "    base_dir,\n",
    "    \"models\",  \n",
    "    NN_architecture,\n",
    "    \"umap_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in UMAP model\n",
    "infile = open(umap_model_file, 'rb')\n",
    "umap_model = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>version https://git-lfs.github.com/spec/v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>oid sha256:0ed2a9ce76edd0955c7ad180585c0a011270b7de0cb89ff5915cc1131ea53d4c</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size 353571891</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [oid sha256:0ed2a9ce76edd0955c7ad180585c0a011270b7de0cb89ff5915cc1131ea53d4c, size 353571891]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "simulated_data = pd.read_table(\n",
    "    simulated_data_file,\n",
    "    header=0, \n",
    "    index_col=0,\n",
    "    sep='\\t')\n",
    "\n",
    "simulated_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Similarity using high dimensional (5K) batched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating SVCCA score for 1 batch vs 1 batches..\n",
      "Using batch 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3a1028626c65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     svcca_results = cca_core.get_cca_similarity(original_data_df.T,\n\u001b[1;32m     46\u001b[0m                                           \u001b[0mbatch_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                                           verbose=False)\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0moutput_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvcca_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cca_coef1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repos/Batch_effects_simulation/scripts/experiment_0_generate_simulated_data/functions/cca_core.py\u001b[0m in \u001b[0;36mget_cca_similarity\u001b[0;34m(acts1, acts2, threshold, compute_dirns, verbose)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;31m# rescale covariance to make cca computation more stable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m   \u001b[0mxmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmaxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m   \u001b[0mymax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmayy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m   \u001b[0msigmaxx\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mxmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/batch_effects/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2332\u001b[0m     \"\"\"\n\u001b[1;32m   2333\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out, keepdims=keepdims,\n\u001b[0;32m-> 2334\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/batch_effects/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "output_list = []\n",
    "\n",
    "for i in num_batches:\n",
    "    print('Calculating SVCCA score for 1 batch vs {} batches..'.format(i))\n",
    "    \n",
    "    # Get batch 1\n",
    "    batch_1_file = os.path.join(\n",
    "        batch_dir,\n",
    "        \"Batch_1.txt\")\n",
    "\n",
    "    batch_1 = pd.read_table(\n",
    "        batch_1_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "\n",
    "    # PCA projection\n",
    "    pca = PCA(n_components=num_PCs)\n",
    "\n",
    "    # Use trained model to encode expression data into SAME latent space\n",
    "    original_data_df =  batch_1\n",
    "    \n",
    "    # All batches\n",
    "    batch_other_file = os.path.join(\n",
    "        batch_dir,\n",
    "        \"Batch_\"+str(i)+\".txt\")\n",
    "\n",
    "    batch_other = pd.read_table(\n",
    "        batch_other_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "    \n",
    "    print(\"Using batch {}\".format(i))\n",
    "    \n",
    "    # Use trained model to encode expression data into SAME latent space\n",
    "    batch_data_df =  batch_other\n",
    "    \n",
    "    # Check shape\n",
    "    if original_data_df.shape[0] != batch_data_df.shape[0]:\n",
    "        diff = original_data_df.shape[0] - batch_data_df.shape[0]\n",
    "        original_data_df = original_data_df.iloc[:-diff,:]\n",
    "    \n",
    "    # SVCCA\n",
    "    svcca_results = cca_core.get_cca_similarity(original_data_df.T,\n",
    "                                          batch_data_df.T,\n",
    "                                          verbose=False)\n",
    "    \n",
    "    output_list.append(np.mean(svcca_results[\"cca_coef1\"]))\n",
    "\n",
    "# Convert output to pandas dataframe\n",
    "svcca_raw_df = pd.DataFrame(output_list, columns=[\"svcca_mean_similarity\"], index=num_batches)\n",
    "svcca_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "svcca_raw_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check positive control\n",
    "We want to verify that SVCCA(input, input) = 1.  This does not seem to be the case, but I'm not sure why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datasets batch 1 and original are the same\n",
    "batch_1_file = os.path.join(\n",
    "    batch_dir,\n",
    "    \"Batch_1.txt\")\n",
    "print(batch_1_file)\n",
    "\n",
    "batch_1 = pd.read_table(\n",
    "    batch_1_file,\n",
    "    header=0,\n",
    "    sep='\\t',\n",
    "    index_col=0)\n",
    "    \n",
    "batch_1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "batch_other_file = os.path.join(\n",
    "    batch_dir,\n",
    "    \"Batch_\"+str(i)+\".txt\")\n",
    "print(batch_other_file)\n",
    "\n",
    "batch_other = pd.read_table(\n",
    "    batch_other_file,\n",
    "    header=0,\n",
    "    sep='\\t',\n",
    "    index_col=0)\n",
    "\n",
    "batch_other.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SVCCA(batch_1, batch_1)\n",
    "svcca_results_batch1_itself = cca_core.get_cca_similarity(batch_1.T,\n",
    "                                          batch_1.T,\n",
    "                                          verbose=False)\n",
    "np.mean(svcca_results_batch1_itself[\"cca_coef1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caluclate SVCCA(batch_1, batch_1 variable)\n",
    "svcca_results_batch1_other = cca_core.get_cca_similarity(batch_1.T,\n",
    "                                          batch_other.T,\n",
    "                                          verbose=False)\n",
    "np.mean(svcca_results_batch1_other[\"cca_coef1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Similarity using PCA projection of batched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list = []\n",
    "\n",
    "for i in num_batches:\n",
    "    print('Calculating SVCCA score for 1 batch vs {} batches..'.format(i))\n",
    "    \n",
    "    # Get batch 1\n",
    "    batch_1_file = os.path.join(\n",
    "        batch_dir,\n",
    "        \"Batch_1.txt\")\n",
    "\n",
    "    batch_1 = pd.read_table(\n",
    "        batch_1_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "\n",
    "    # PCA projection\n",
    "    pca = PCA(n_components=num_PCs)\n",
    "\n",
    "    # Use trained model to encode expression data into SAME latent space\n",
    "    original_data_PCAencoded = pca.fit_transform(batch_1)\n",
    "\n",
    "\n",
    "    original_data_PCAencoded_df = pd.DataFrame(original_data_PCAencoded,\n",
    "                                         index=batch_1.index\n",
    "                                         )\n",
    "    \n",
    "    # All batches\n",
    "    batch_other_file = os.path.join(\n",
    "        batch_dir,\n",
    "        \"Batch_\"+str(i)+\".txt\")\n",
    "\n",
    "    batch_other = pd.read_table(\n",
    "        batch_other_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "    \n",
    "    print(\"Using batch {}\".format(i))\n",
    "    \n",
    "    # Use trained model to encode expression data into SAME latent space\n",
    "    batch_data_PCAencoded = pca.fit_transform(batch_other)\n",
    "    \n",
    "    \n",
    "    batch_data_PCAencoded_df = pd.DataFrame(batch_data_PCAencoded,\n",
    "                                         index=batch_other.index\n",
    "                                         )\n",
    "        \n",
    "    # Check shape\n",
    "    if original_data_PCAencoded_df.shape[0] != batch_data_PCAencoded_df.shape[0]:\n",
    "        diff = original_data_PCAencoded_df.shape[0] - batch_data_PCAencoded_df.shape[0]\n",
    "        original_data_PCAencoded_df = original_data_PCAencoded_df.iloc[:-diff,:]\n",
    "    \n",
    "    # SVCCA\n",
    "    svcca_results = cca_core.get_cca_similarity(original_data_PCAencoded_df.T,\n",
    "                                          batch_data_PCAencoded_df.T,\n",
    "                                          verbose=False)\n",
    "    \n",
    "    output_list.append(np.mean(svcca_results[\"cca_coef1\"]))\n",
    "\n",
    "# Convert output to pandas dataframe\n",
    "svcca_pca_df = pd.DataFrame(output_list, columns=[\"svcca_mean_similarity\"], index=num_batches)\n",
    "svcca_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "svcca_pca_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually compute similarity by applying CCA to PC batched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca = CCA(n_components=1)\n",
    "\n",
    "output_list = []\n",
    "\n",
    "for i in num_batches:\n",
    "    print('Calculating SVCCA score for 1 batch vs {} batches..'.format(i))\n",
    "    \n",
    "    # Get batch 1\n",
    "    batch_1_file = os.path.join(\n",
    "        batch_dir,\n",
    "        \"Batch_1.txt\")\n",
    "\n",
    "    batch_1 = pd.read_table(\n",
    "        batch_1_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "\n",
    "    # PCA projection\n",
    "    pca = PCA(n_components=num_PCs)\n",
    "\n",
    "    # Use trained model to encode expression data into SAME latent space\n",
    "    original_data_PCAencoded = pca.fit_transform(batch_1)\n",
    "\n",
    "\n",
    "    original_data_PCAencoded_df = pd.DataFrame(original_data_PCAencoded,\n",
    "                                         index=batch_1.index\n",
    "                                         )\n",
    "    \n",
    "    # All batches\n",
    "    batch_other_file = os.path.join(\n",
    "        batch_dir,\n",
    "        \"Batch_\"+str(i)+\".txt\")\n",
    "\n",
    "    batch_other = pd.read_table(\n",
    "        batch_other_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "    \n",
    "    print(\"Using batch {}\".format(i))\n",
    "    \n",
    "    # Use trained model to encode expression data into SAME latent space\n",
    "    batch_data_PCAencoded = pca.fit_transform(batch_other)\n",
    "    \n",
    "    \n",
    "    batch_data_PCAencoded_df = pd.DataFrame(batch_data_PCAencoded,\n",
    "                                         index=batch_other.index\n",
    "                                         )\n",
    "        \n",
    "    # Check shape\n",
    "    if original_data_PCAencoded_df.shape[0] != batch_data_PCAencoded_df.shape[0]:\n",
    "        diff = original_data_PCAencoded_df.shape[0] - batch_data_PCAencoded_df.shape[0]\n",
    "        original_data_PCAencoded_df = original_data_PCAencoded_df.iloc[:-diff,:]\n",
    "    \n",
    "    # CCA\n",
    "    U_c, V_c = cca.fit_transform(original_data_PCAencoded_df, batch_data_PCAencoded_df)\n",
    "    result = np.corrcoef(U_c.T, V_c.T)[0,1]\n",
    "    \n",
    "    output_list.append(result)\n",
    "\n",
    "# Convert output to pandas dataframe\n",
    "pca_cca_df = pd.DataFrame(output_list, columns=[\"svcca_mean_similarity\"], index=num_batches)\n",
    "pca_cca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "pca_cca_df.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:batch_effects]",
   "language": "python",
   "name": "conda-env-batch_effects-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
