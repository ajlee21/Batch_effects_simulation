{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity analysis\n",
    "\n",
    "We want to determine if the different batch simulated data is able to capture the biological signal that is present in the original data:  How much of the real input data is captured in the simulated batch data?\n",
    "\n",
    "In other words, we want to compare the representation of the real input data and the simulated batch data.  We will use **SVCCA** to compare these two representations.\n",
    "\n",
    "Here, we apply Singular Vector Canonical Correlation Analysis [Raghu et al. 2017](https://arxiv.org/pdf/1706.05806.pdf) [(github)](https://github.com/google/svcca) to the UMAP and PCA representations of our batch 1 simulated dataset vs batch n simulated datasets.  The output of the SVCCA analysis is the SVCCA mean similarity score. This single number can be interpreted as a measure of similarity between our original data vs batched dataset.\n",
    "\n",
    "Briefly, SVCCA uses Singular Value Decomposition (SVD) to extract the components explaining 99% of the variation. This is done to remove potential dimensions described by noise. Next, SVCCA performs a Canonical Correlation Analysis (CCA) on the SVD matrices to identify maximum correlations of linear combinations of both input matrices. The algorithm will identify the canonical correlations of highest magnitude across and within algorithms of the same dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import umap\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from ggplot import *\n",
    "from functions import cca_core\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from numpy.random import seed\n",
    "randomState = 123\n",
    "seed(randomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "config_file = \"config_exp_0.txt\"\n",
    "\n",
    "d = {}\n",
    "float_params = [\"learning_rate\", \"kappa\", \"epsilon_std\"]\n",
    "str_params = [\"analysis_name\", \"NN_architecture\"]\n",
    "lst_params = [\"num_batches\"]\n",
    "with open(config_file) as f:\n",
    "    for line in f:\n",
    "        (name, val) = line.split()\n",
    "        if name in float_params:\n",
    "            d[name] = float(val)\n",
    "        elif name in str_params:\n",
    "            d[name] = str(val)\n",
    "        elif name in lst_params:\n",
    "            d[name] = ast.literal_eval(val)\n",
    "        else:\n",
    "            d[name] = int(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "analysis_name = d[\"analysis_name\"]\n",
    "NN_architecture = d[\"NN_architecture\"]\n",
    "num_PCs = d[\"num_PCs\"]\n",
    "num_batches = d[\"num_batches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(),\"../..\"))\n",
    "\n",
    "simulated_data_file = os.path.join(\n",
    "    base_dir,\n",
    "    \"data\",\n",
    "    \"simulated\",\n",
    "    analysis_name,\n",
    "    \"simulated_data.txt.xz\")\n",
    "\n",
    "batch_dir = os.path.join(\n",
    "    base_dir,\n",
    "    \"data\",\n",
    "    \"batch_simulated\",\n",
    "    analysis_name)\n",
    "\n",
    "umap_model_file = umap_model_file = os.path.join(\n",
    "    base_dir,\n",
    "    \"models\",  \n",
    "    NN_architecture,\n",
    "    \"umap_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in UMAP model\n",
    "infile = open(umap_model_file, 'rb')\n",
    "umap_model = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5340</th>\n",
       "      <th>339</th>\n",
       "      <th>244</th>\n",
       "      <th>1567</th>\n",
       "      <th>1827</th>\n",
       "      <th>4981</th>\n",
       "      <th>2310</th>\n",
       "      <th>3929</th>\n",
       "      <th>1498</th>\n",
       "      <th>3226</th>\n",
       "      <th>...</th>\n",
       "      <th>2641</th>\n",
       "      <th>4645</th>\n",
       "      <th>4585</th>\n",
       "      <th>1696</th>\n",
       "      <th>5218</th>\n",
       "      <th>249</th>\n",
       "      <th>2655</th>\n",
       "      <th>4782</th>\n",
       "      <th>1293</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.535602</td>\n",
       "      <td>0.503128</td>\n",
       "      <td>0.285015</td>\n",
       "      <td>0.182251</td>\n",
       "      <td>0.338972</td>\n",
       "      <td>0.563961</td>\n",
       "      <td>0.324290</td>\n",
       "      <td>0.469941</td>\n",
       "      <td>0.185681</td>\n",
       "      <td>0.090720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358896</td>\n",
       "      <td>0.654506</td>\n",
       "      <td>0.352168</td>\n",
       "      <td>0.213065</td>\n",
       "      <td>0.555343</td>\n",
       "      <td>0.346773</td>\n",
       "      <td>0.231398</td>\n",
       "      <td>0.207239</td>\n",
       "      <td>0.548592</td>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.602998</td>\n",
       "      <td>0.314449</td>\n",
       "      <td>0.170274</td>\n",
       "      <td>0.150126</td>\n",
       "      <td>0.393875</td>\n",
       "      <td>0.425789</td>\n",
       "      <td>0.359611</td>\n",
       "      <td>0.367097</td>\n",
       "      <td>0.162651</td>\n",
       "      <td>0.060858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411636</td>\n",
       "      <td>0.569583</td>\n",
       "      <td>0.461774</td>\n",
       "      <td>0.141425</td>\n",
       "      <td>0.559661</td>\n",
       "      <td>0.404262</td>\n",
       "      <td>0.193320</td>\n",
       "      <td>0.256343</td>\n",
       "      <td>0.604435</td>\n",
       "      <td>0.563223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.517498</td>\n",
       "      <td>0.419739</td>\n",
       "      <td>0.182155</td>\n",
       "      <td>0.131460</td>\n",
       "      <td>0.324510</td>\n",
       "      <td>0.413850</td>\n",
       "      <td>0.320531</td>\n",
       "      <td>0.416758</td>\n",
       "      <td>0.152202</td>\n",
       "      <td>0.088437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354576</td>\n",
       "      <td>0.599023</td>\n",
       "      <td>0.410843</td>\n",
       "      <td>0.257731</td>\n",
       "      <td>0.510072</td>\n",
       "      <td>0.403116</td>\n",
       "      <td>0.197580</td>\n",
       "      <td>0.239914</td>\n",
       "      <td>0.713293</td>\n",
       "      <td>0.624423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.397841</td>\n",
       "      <td>0.457606</td>\n",
       "      <td>0.323778</td>\n",
       "      <td>0.249936</td>\n",
       "      <td>0.297673</td>\n",
       "      <td>0.476715</td>\n",
       "      <td>0.381297</td>\n",
       "      <td>0.468330</td>\n",
       "      <td>0.215541</td>\n",
       "      <td>0.132116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451938</td>\n",
       "      <td>0.411013</td>\n",
       "      <td>0.378725</td>\n",
       "      <td>0.290338</td>\n",
       "      <td>0.430163</td>\n",
       "      <td>0.377278</td>\n",
       "      <td>0.377678</td>\n",
       "      <td>0.328690</td>\n",
       "      <td>0.521566</td>\n",
       "      <td>0.390877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.535997</td>\n",
       "      <td>0.465947</td>\n",
       "      <td>0.277286</td>\n",
       "      <td>0.222062</td>\n",
       "      <td>0.385123</td>\n",
       "      <td>0.421842</td>\n",
       "      <td>0.330086</td>\n",
       "      <td>0.415129</td>\n",
       "      <td>0.177301</td>\n",
       "      <td>0.128083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495980</td>\n",
       "      <td>0.525113</td>\n",
       "      <td>0.432366</td>\n",
       "      <td>0.201250</td>\n",
       "      <td>0.606396</td>\n",
       "      <td>0.380384</td>\n",
       "      <td>0.209951</td>\n",
       "      <td>0.288402</td>\n",
       "      <td>0.563646</td>\n",
       "      <td>0.583976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.493290</td>\n",
       "      <td>0.396501</td>\n",
       "      <td>0.249366</td>\n",
       "      <td>0.159639</td>\n",
       "      <td>0.375957</td>\n",
       "      <td>0.402583</td>\n",
       "      <td>0.275842</td>\n",
       "      <td>0.381382</td>\n",
       "      <td>0.261653</td>\n",
       "      <td>0.081041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342845</td>\n",
       "      <td>0.670070</td>\n",
       "      <td>0.407004</td>\n",
       "      <td>0.215835</td>\n",
       "      <td>0.587762</td>\n",
       "      <td>0.397528</td>\n",
       "      <td>0.236528</td>\n",
       "      <td>0.251614</td>\n",
       "      <td>0.600678</td>\n",
       "      <td>0.718417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.433612</td>\n",
       "      <td>0.351818</td>\n",
       "      <td>0.241003</td>\n",
       "      <td>0.179525</td>\n",
       "      <td>0.336945</td>\n",
       "      <td>0.345377</td>\n",
       "      <td>0.321877</td>\n",
       "      <td>0.382335</td>\n",
       "      <td>0.167349</td>\n",
       "      <td>0.141031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442284</td>\n",
       "      <td>0.484055</td>\n",
       "      <td>0.402640</td>\n",
       "      <td>0.323867</td>\n",
       "      <td>0.504018</td>\n",
       "      <td>0.418877</td>\n",
       "      <td>0.241006</td>\n",
       "      <td>0.274514</td>\n",
       "      <td>0.596295</td>\n",
       "      <td>0.556387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.451588</td>\n",
       "      <td>0.457565</td>\n",
       "      <td>0.336580</td>\n",
       "      <td>0.272774</td>\n",
       "      <td>0.264118</td>\n",
       "      <td>0.369123</td>\n",
       "      <td>0.275050</td>\n",
       "      <td>0.424156</td>\n",
       "      <td>0.250198</td>\n",
       "      <td>0.247813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417076</td>\n",
       "      <td>0.499973</td>\n",
       "      <td>0.297584</td>\n",
       "      <td>0.261137</td>\n",
       "      <td>0.453874</td>\n",
       "      <td>0.425273</td>\n",
       "      <td>0.294926</td>\n",
       "      <td>0.293479</td>\n",
       "      <td>0.535604</td>\n",
       "      <td>0.471286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.619654</td>\n",
       "      <td>0.442385</td>\n",
       "      <td>0.281102</td>\n",
       "      <td>0.209915</td>\n",
       "      <td>0.417300</td>\n",
       "      <td>0.559756</td>\n",
       "      <td>0.303963</td>\n",
       "      <td>0.474562</td>\n",
       "      <td>0.233043</td>\n",
       "      <td>0.112126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436053</td>\n",
       "      <td>0.675932</td>\n",
       "      <td>0.392779</td>\n",
       "      <td>0.213318</td>\n",
       "      <td>0.691767</td>\n",
       "      <td>0.300163</td>\n",
       "      <td>0.260528</td>\n",
       "      <td>0.281530</td>\n",
       "      <td>0.509397</td>\n",
       "      <td>0.618331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.434846</td>\n",
       "      <td>0.361911</td>\n",
       "      <td>0.255196</td>\n",
       "      <td>0.199091</td>\n",
       "      <td>0.345327</td>\n",
       "      <td>0.390971</td>\n",
       "      <td>0.342980</td>\n",
       "      <td>0.392987</td>\n",
       "      <td>0.176265</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465793</td>\n",
       "      <td>0.475744</td>\n",
       "      <td>0.384862</td>\n",
       "      <td>0.209843</td>\n",
       "      <td>0.521720</td>\n",
       "      <td>0.375902</td>\n",
       "      <td>0.241566</td>\n",
       "      <td>0.250671</td>\n",
       "      <td>0.527586</td>\n",
       "      <td>0.522440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       5340       339       244      1567      1827      4981      2310  \\\n",
       "0  0.535602  0.503128  0.285015  0.182251  0.338972  0.563961  0.324290   \n",
       "1  0.602998  0.314449  0.170274  0.150126  0.393875  0.425789  0.359611   \n",
       "2  0.517498  0.419739  0.182155  0.131460  0.324510  0.413850  0.320531   \n",
       "3  0.397841  0.457606  0.323778  0.249936  0.297673  0.476715  0.381297   \n",
       "4  0.535997  0.465947  0.277286  0.222062  0.385123  0.421842  0.330086   \n",
       "5  0.493290  0.396501  0.249366  0.159639  0.375957  0.402583  0.275842   \n",
       "6  0.433612  0.351818  0.241003  0.179525  0.336945  0.345377  0.321877   \n",
       "7  0.451588  0.457565  0.336580  0.272774  0.264118  0.369123  0.275050   \n",
       "8  0.619654  0.442385  0.281102  0.209915  0.417300  0.559756  0.303963   \n",
       "9  0.434846  0.361911  0.255196  0.199091  0.345327  0.390971  0.342980   \n",
       "\n",
       "       3929      1498      3226    ...         2641      4645      4585  \\\n",
       "0  0.469941  0.185681  0.090720    ...     0.358896  0.654506  0.352168   \n",
       "1  0.367097  0.162651  0.060858    ...     0.411636  0.569583  0.461774   \n",
       "2  0.416758  0.152202  0.088437    ...     0.354576  0.599023  0.410843   \n",
       "3  0.468330  0.215541  0.132116    ...     0.451938  0.411013  0.378725   \n",
       "4  0.415129  0.177301  0.128083    ...     0.495980  0.525113  0.432366   \n",
       "5  0.381382  0.261653  0.081041    ...     0.342845  0.670070  0.407004   \n",
       "6  0.382335  0.167349  0.141031    ...     0.442284  0.484055  0.402640   \n",
       "7  0.424156  0.250198  0.247813    ...     0.417076  0.499973  0.297584   \n",
       "8  0.474562  0.233043  0.112126    ...     0.436053  0.675932  0.392779   \n",
       "9  0.392987  0.176265  0.135802    ...     0.465793  0.475744  0.384862   \n",
       "\n",
       "       1696      5218       249      2655      4782      1293       767  \n",
       "0  0.213065  0.555343  0.346773  0.231398  0.207239  0.548592  0.610000  \n",
       "1  0.141425  0.559661  0.404262  0.193320  0.256343  0.604435  0.563223  \n",
       "2  0.257731  0.510072  0.403116  0.197580  0.239914  0.713293  0.624423  \n",
       "3  0.290338  0.430163  0.377278  0.377678  0.328690  0.521566  0.390877  \n",
       "4  0.201250  0.606396  0.380384  0.209951  0.288402  0.563646  0.583976  \n",
       "5  0.215835  0.587762  0.397528  0.236528  0.251614  0.600678  0.718417  \n",
       "6  0.323867  0.504018  0.418877  0.241006  0.274514  0.596295  0.556387  \n",
       "7  0.261137  0.453874  0.425273  0.294926  0.293479  0.535604  0.471286  \n",
       "8  0.213318  0.691767  0.300163  0.260528  0.281530  0.509397  0.618331  \n",
       "9  0.209843  0.521720  0.375902  0.241566  0.250671  0.527586  0.522440  \n",
       "\n",
       "[10 rows x 1000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "simulated_data = pd.read_table(\n",
    "    simulated_data_file,\n",
    "    header=0, \n",
    "    index_col=0,\n",
    "    sep='\\t')\n",
    "\n",
    "simulated_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Similarity using high dimensional (5K) batched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating SVCCA score for 1 batch vs 1 batches..\n"
     ]
    },
    {
     "ename": "LZMAError",
     "evalue": "Input format not supported by decoder",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLZMAError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/batch_effects/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/batch_effects/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/batch_effects/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/batch_effects/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/batch_effects/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/batch_effects/lib/python3.5/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/batch_effects/lib/python3.5/_compression.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0mrawblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLZMAError\u001b[0m: Input format not supported by decoder"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate similarity using SVCCA\n",
    "\n",
    "# Store svcca scores\n",
    "output_list = []\n",
    "\n",
    "for i in num_batches:\n",
    "    print('Calculating SVCCA score for 1 batch vs {} batches..'.format(i))\n",
    "    \n",
    "    # Get batch 1\n",
    "    batch_1_file = os.path.join(\n",
    "        batch_dir,\n",
    "        \"Batch_1.txt.xz\")\n",
    "\n",
    "    batch_1 = pd.read_table(\n",
    "        batch_1_file,\n",
    "        header=0,\n",
    "        index_col=0,\n",
    "        sep='\\t')\n",
    "\n",
    "    # Use trained model to encode expression data into SAME latent space\n",
    "    original_data_df =  batch_1\n",
    "    \n",
    "    # All batches\n",
    "    batch_other_file = os.path.join(\n",
    "        batch_dir,\n",
    "        \"Batch_\"+str(i)+\".txt.xz\")\n",
    "\n",
    "    batch_other = pd.read_table(\n",
    "        batch_other_file,\n",
    "        header=0,\n",
    "        index_col=0,\n",
    "        sep='\\t')\n",
    "    \n",
    "    print(\"Using batch {}\".format(i))\n",
    "    \n",
    "    # Use trained model to encode expression data into SAME latent space\n",
    "    batch_data_df =  batch_other\n",
    "    \n",
    "    # Check shape: ensure that the number of samples is the same between the two datasets\n",
    "    if original_data_df.shape[0] != batch_data_df.shape[0]:\n",
    "        diff = original_data_df.shape[0] - batch_data_df.shape[0]\n",
    "        original_data_df = original_data_df.iloc[:-diff,:]\n",
    "    \n",
    "    # SVCCA\n",
    "    svcca_results = cca_core.get_cca_similarity(original_data_df.T,\n",
    "                                          batch_data_df.T,\n",
    "                                          verbose=False)\n",
    "    \n",
    "    output_list.append(np.mean(svcca_results[\"cca_coef1\"]))\n",
    "\n",
    "# Convert output to pandas dataframe\n",
    "svcca_raw_df = pd.DataFrame(output_list, columns=[\"svcca_mean_similarity\"], index=num_batches)\n",
    "svcca_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.15 s, sys: 67.6 ms, total: 4.21 s\n",
      "Wall time: 4.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Permute simulated data\n",
    "shuffled_simulated_arr = []\n",
    "num_samples = simulated_data.shape[0]\n",
    "\n",
    "for i in range(num_samples):\n",
    "    row = list(simulated_data.values[i])\n",
    "    shuffled_simulated_row = random.sample(row, len(row))\n",
    "    shuffled_simulated_arr.append(shuffled_simulated_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shuffled_simulated_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shuffled_simulated_data' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SVCCA\n",
    "svcca_results = cca_core.get_cca_similarity(simulated_data.T,\n",
    "                                      shuffled_simulated_data.T,\n",
    "                                      verbose=False)\n",
    "\n",
    "print(np.mean(svcca_results[\"cca_coef1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svcca_raw_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4e44311ba6fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msvcca_raw_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'svcca_raw_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot\n",
    "svcca_raw_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Similarity using PCA projection of batched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "output_list = []\n",
    "\n",
    "for i in num_batches:\n",
    "    print('Calculating SVCCA score for 1 batch vs {} batches..'.format(i))\n",
    "    \n",
    "    # Get batch 1\n",
    "    batch_1_file = os.path.join(\n",
    "        batch_dir,\n",
    "        \"Batch_1.txt\")\n",
    "\n",
    "    batch_1 = pd.read_table(\n",
    "        batch_1_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "\n",
    "    # PCA projection\n",
    "    pca = PCA(n_components=num_PCs)\n",
    "\n",
    "    # Use trained model to encode expression data into SAME latent space\n",
    "    original_data_PCAencoded = pca.fit_transform(batch_1)\n",
    "\n",
    "\n",
    "    original_data_PCAencoded_df = pd.DataFrame(original_data_PCAencoded,\n",
    "                                         index=batch_1.index\n",
    "                                         )\n",
    "    \n",
    "    # All batches\n",
    "    batch_other_file = os.path.join(\n",
    "        batch_dir,\n",
    "        \"Batch_\"+str(i)+\".txt\")\n",
    "\n",
    "    batch_other = pd.read_table(\n",
    "        batch_other_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "    \n",
    "    print(\"Using batch {}\".format(i))\n",
    "    \n",
    "    # Use trained model to encode expression data into SAME latent space\n",
    "    batch_data_PCAencoded = pca.fit_transform(batch_other)\n",
    "    \n",
    "    \n",
    "    batch_data_PCAencoded_df = pd.DataFrame(batch_data_PCAencoded,\n",
    "                                         index=batch_other.index\n",
    "                                         )\n",
    "        \n",
    "    # Check shape\n",
    "    if original_data_PCAencoded_df.shape[0] != batch_data_PCAencoded_df.shape[0]:\n",
    "        diff = original_data_PCAencoded_df.shape[0] - batch_data_PCAencoded_df.shape[0]\n",
    "        original_data_PCAencoded_df = original_data_PCAencoded_df.iloc[:-diff,:]\n",
    "    \n",
    "    # SVCCA\n",
    "    svcca_results = cca_core.get_cca_similarity(original_data_PCAencoded_df.T,\n",
    "                                          batch_data_PCAencoded_df.T,\n",
    "                                          verbose=False)\n",
    "    \n",
    "    output_list.append(np.mean(svcca_results[\"cca_coef1\"]))\n",
    "\n",
    "# Convert output to pandas dataframe\n",
    "svcca_pca_df = pd.DataFrame(output_list, columns=[\"svcca_mean_similarity\"], index=num_batches)\n",
    "svcca_pca_df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Plot\n",
    "svcca_pca_df.plot()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually compute similarity by applying CCA to PC batched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cca = CCA(n_components=1)\n",
    "\n",
    "output_list = []\n",
    "\n",
    "for i in num_batches:\n",
    "    print('Calculating SVCCA score for 1 batch vs {} batches..'.format(i))\n",
    "    \n",
    "    # Get batch 1\n",
    "    batch_1_file = os.path.join(\n",
    "        batch_dir,\n",
    "        \"Batch_1.txt\")\n",
    "\n",
    "    batch_1 = pd.read_table(\n",
    "        batch_1_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "\n",
    "    # PCA projection\n",
    "    pca = PCA(n_components=num_PCs)\n",
    "\n",
    "    # Use trained model to encode expression data into SAME latent space\n",
    "    original_data_PCAencoded = pca.fit_transform(batch_1)\n",
    "\n",
    "\n",
    "    original_data_PCAencoded_df = pd.DataFrame(original_data_PCAencoded,\n",
    "                                         index=batch_1.index\n",
    "                                         )\n",
    "    \n",
    "    # All batches\n",
    "    batch_other_file = os.path.join(\n",
    "        batch_dir,\n",
    "        \"Batch_\"+str(i)+\".txt\")\n",
    "\n",
    "    batch_other = pd.read_table(\n",
    "        batch_other_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "    \n",
    "    print(\"Using batch {}\".format(i))\n",
    "    \n",
    "    # Use trained model to encode expression data into SAME latent space\n",
    "    batch_data_PCAencoded = pca.fit_transform(batch_other)\n",
    "    \n",
    "    \n",
    "    batch_data_PCAencoded_df = pd.DataFrame(batch_data_PCAencoded,\n",
    "                                         index=batch_other.index\n",
    "                                         )\n",
    "        \n",
    "    # Check shape\n",
    "    if original_data_PCAencoded_df.shape[0] != batch_data_PCAencoded_df.shape[0]:\n",
    "        diff = original_data_PCAencoded_df.shape[0] - batch_data_PCAencoded_df.shape[0]\n",
    "        original_data_PCAencoded_df = original_data_PCAencoded_df.iloc[:-diff,:]\n",
    "    \n",
    "    # CCA\n",
    "    U_c, V_c = cca.fit_transform(original_data_PCAencoded_df, batch_data_PCAencoded_df)\n",
    "    result = np.corrcoef(U_c.T, V_c.T)[0,1]\n",
    "    \n",
    "    output_list.append(result)\n",
    "\n",
    "# Convert output to pandas dataframe\n",
    "pca_cca_df = pd.DataFrame(output_list, columns=[\"svcca_mean_similarity\"], index=num_batches)\n",
    "pca_cca_df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Plot\n",
    "pca_cca_df.plot()\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:batch_effects]",
   "language": "python",
   "name": "conda-env-batch_effects-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
