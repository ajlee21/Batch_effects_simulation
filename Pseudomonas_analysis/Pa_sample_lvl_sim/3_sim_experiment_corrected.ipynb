{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation experiment using noise-corrected data\n",
    "\n",
    "Run entire simulation experiment multiple times to generate confidence interval.  The simulation experiment can be found in ```functions/pipeline.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from functions import pipelines\n",
    "\n",
    "from numpy.random import seed\n",
    "randomState = 123\n",
    "seed(randomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "dataset_name = \"Pseudomonas_analysis\"\n",
    "analysis_name = 'Pa_sample_lvl_sim'\n",
    "NN_architecture = 'NN_2500_30'\n",
    "file_prefix = 'Experiment_corrected'\n",
    "num_simulated_samples = 6000\n",
    "lst_num_experiments = [1, 2, 5, 10, 20,\n",
    " 50, 100, 500, 1000, 2000, 3000, 6000]\n",
    "\n",
    "\n",
    "corrected = True\n",
    "use_pca = True\n",
    "num_PCs = 10\n",
    "local_dir = os.path.abspath(\n",
    "      os.path.join(\n",
    "          os.getcwd(), \"../../../../\"))\n",
    "\n",
    "iterations = range(5) \n",
    "num_cores = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files\n",
    "base_dir = os.path.abspath(\n",
    "  os.path.join(\n",
    "      os.getcwd(), \"../..\"))    # base dir on repo\n",
    "\n",
    "\n",
    "normalized_data_file = os.path.join(\n",
    "    base_dir,\n",
    "    dataset_name,\n",
    "    \"data\",\n",
    "    \"input\",\n",
    "    \"train_set_normalized.pcl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output files\n",
    "similarity_corrected_file = os.path.join(\n",
    "    base_dir,\n",
    "    \"results\",\n",
    "    \"saved_variables\",\n",
    "    \"Pa_sample_lvl_sim_similarity_corrected.pickle\")\n",
    "\n",
    "ci_corrected_file = os.path.join(\n",
    "    base_dir,\n",
    "    \"results\",\n",
    "    \"saved_variables\",\n",
    "    \"Pa_sample_lvl_sim_ci_corrected.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Run multiple simulations\n",
    "results = Parallel(n_jobs=num_cores, verbose=100)(\n",
    "    delayed(\n",
    "        pipelines.sample_level_simulation_corrected)(i,\n",
    "                                                     NN_architecture,\n",
    "                                                     dataset_name,\n",
    "                                                     analysis_name,\n",
    "                                                     num_simulated_samples,\n",
    "                                                     lst_num_experiments,\n",
    "                                                     corrected,\n",
    "                                                     use_pca,\n",
    "                                                     num_PCs,\n",
    "                                                     file_prefix,\n",
    "                                                     normalized_data_file,\n",
    "                                                     local_dir) for i in iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concatenate output dataframes\n",
    "all_svcca_scores = pd.DataFrame()\n",
    "\n",
    "for i in iterations:\n",
    "    all_svcca_scores = pd.concat([all_svcca_scores, results[i][1]], axis=1)\n",
    "\n",
    "all_svcca_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get median for each row (number of experiments)\n",
    "mean_scores = all_svcca_scores.mean(axis=1).to_frame()\n",
    "mean_scores.columns = ['score']\n",
    "mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get standard dev for each row (number of experiments)\n",
    "import math\n",
    "std_scores = (all_svcca_scores.std(axis=1)/math.sqrt(10)).to_frame()\n",
    "std_scores.columns = ['score']\n",
    "std_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get confidence interval for each row (number of experiments)\n",
    "# z-score for 95% confidence interval\n",
    "err = std_scores*1.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get boundaries of confidence interval\n",
    "ymax = mean_scores + err\n",
    "ymin = mean_scores - err\n",
    "\n",
    "ci = pd.concat([ymin, ymax], axis=1)\n",
    "ci.columns = ['ymin', 'ymax']\n",
    "ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle dataframe of mean scores scores for first run, interval\n",
    "mean_scores.to_pickle(similarity_corrected_file)\n",
    "ci.to_pickle(ci_corrected_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:batch_effects]",
   "language": "python",
   "name": "conda-env-batch_effects-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
