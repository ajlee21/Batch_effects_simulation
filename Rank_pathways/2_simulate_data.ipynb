{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate data\n",
    "This notebook generates simulated experiments by sampling from the VAE using the user selected template experiment as a guide for sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandra/anaconda3/envs/ranked_pathways/lib/python3.7/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from keras.models import load_model\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "\n",
    "from plotnine import (ggplot,\n",
    "                      labs,  \n",
    "                      geom_line, \n",
    "                      geom_point,\n",
    "                      geom_errorbar,\n",
    "                      aes, \n",
    "                      ggsave, \n",
    "                      theme_bw,\n",
    "                      theme,\n",
    "                      xlim,\n",
    "                      ylim,\n",
    "                      facet_wrap,\n",
    "                      scale_color_manual,\n",
    "                      guides, \n",
    "                      guide_legend,\n",
    "                      element_blank,\n",
    "                      element_text,\n",
    "                      element_rect,\n",
    "                      element_line,\n",
    "                      coords)\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from functions import utils, generate_labeled_data\n",
    "\n",
    "from numpy.random import seed\n",
    "randomState = 123\n",
    "seed(randomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in config variables\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(),\"../\"))\n",
    "\n",
    "config_file = os.path.abspath(os.path.join(base_dir,\n",
    "                                           \"Rank_pathways\",\n",
    "                                           \"init_config.tsv\"))\n",
    "params = utils.read_config(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load params\n",
    "local_dir = params[\"local_dir\"]\n",
    "dataset_name = params['dataset_name']\n",
    "NN_architecture = params['NN_architecture']\n",
    "num_runs = params['num_simulated']\n",
    "project_id = params['project_id']\n",
    "\n",
    "NN_dir = os.path.join(\n",
    "    base_dir, \n",
    "    dataset_name, \n",
    "    \"models\", \n",
    "    NN_architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load real compendium\n",
    "compendium_file = os.path.join(\n",
    "    local_dir,\n",
    "    \"recount2_compedium_data.tsv\")\n",
    "\n",
    "normalized_compendium_file = os.path.join(\n",
    "    local_dir,\n",
    "    \"normalized_recount2_compendium_data.tsv\")\n",
    "\n",
    "# Load real template experiment\n",
    "template_data_file = os.path.join(\n",
    "    local_dir,\n",
    "    \"recount2_template_data.tsv\")\n",
    "\n",
    "# Load pickled files\n",
    "scaler_transform_file = os.path.join(\n",
    "    local_dir,\n",
    "    \"scaler_transform.pickle\")\n",
    "\n",
    "scaler = pickle.load(open(scaler_transform_file, \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "compendium = pd.read_csv(\n",
    "    compendium_file,\n",
    "    header=0,\n",
    "    sep='\\t',\n",
    "    index_col=0)\n",
    "\n",
    "normalized_compendium = pd.read_csv(\n",
    "    normalized_compendium_file,\n",
    "    header=0,\n",
    "    sep='\\t',\n",
    "    index_col=0)\n",
    "\n",
    "template_data = pd.read_csv(\n",
    "    template_data_file,\n",
    "    header=0,\n",
    "    sep='\\t',\n",
    "    index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate experiments using selected template experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/ranked_pathways/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have shape (17810,) but got array with shape (17851,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9e3d860517f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlocal_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         i)\n\u001b[0m",
      "\u001b[0;32m~/Documents/Repos/simulate-expression-compendia/functions/generate_labeled_data.py\u001b[0m in \u001b[0;36mshift_template_experiment\u001b[0;34m(normalized_data_file, selected_experiment_id, NN_architecture, dataset_name, scaler, local_dir, base_dir, run)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Encode selected experiment into latent space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mdata_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_data_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m     data_encoded_df = pd.DataFrame(\n\u001b[1;32m    407\u001b[0m         data_encoded, index=selected_data_df.index)\n",
      "\u001b[0;32m~/anaconda3/envs/ranked_pathways/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1572\u001b[0m             \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m         \"\"\"\n\u001b[0;32m-> 1574\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ranked_pathways/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ranked_pathways/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have shape (17810,) but got array with shape (17851,)"
     ]
    }
   ],
   "source": [
    "# Simulate experiments\n",
    "# Make sure range is correct\n",
    "# Generate multiple simulated datasets\n",
    "for i in range(num_runs):\n",
    "    generate_labeled_data.shift_template_experiment(\n",
    "        normalized_compendium_file,\n",
    "        project_id,\n",
    "        NN_architecture,\n",
    "        dataset_name,\n",
    "        scaler,\n",
    "        local_dir,\n",
    "        base_dir,\n",
    "        i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load shared genes\n",
    "shared_genes_file = os.path.join(\n",
    "    local_dir,\n",
    "    \"shared_gene_ids.pickle\")\n",
    "\n",
    "shared_genes = pickle.load(open(shared_genes_file, \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate simulated experiments\n",
    "smRNA_samples = [\"SRR493961\",\n",
    "                 \"SRR493962\",\n",
    "                 \"SRR493963\",\n",
    "                 \"SRR493964\",\n",
    "                 \"SRR493965\",\n",
    "                 \"SRR493966\",\n",
    "                 \"SRR493967\",\n",
    "                 \"SRR493968\",\n",
    "                 \"SRR493969\",\n",
    "                 \"SRR493970\",\n",
    "                 \"SRR493971\",\n",
    "                 \"SRR493972\"]\n",
    "\n",
    "for i in range(num_runs):\n",
    "    simulated_data_file = os.path.join(\n",
    "        local_dir, \n",
    "        \"pseudo_experiment\",\n",
    "        \"selected_simulated_data_\"+project_id+\"_\"+str(i)+\".txt\")\n",
    "    \n",
    "    # Read simulated data\n",
    "    simulated_data = pd.read_csv(\n",
    "        simulated_data_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "    \n",
    "    # Drop samples\n",
    "    simulated_data = simulated_data.drop(smRNA_samples)\n",
    "    # Drop genes\n",
    "    simulated_data = simulated_data[shared_genes]\n",
    "    \n",
    "    # Save \n",
    "    simulated_data.to_csv(simulated_data_file, float_format='%.5f', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick validation of simulated experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spot check expression values**\n",
    "1. Values are different between different simulated data files (meaning it was a different simulated dataset), and different from the template experiment\n",
    "2. Range of values is scaled the same as the compendium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compendium\n",
    "print(compendium.shape)\n",
    "compendium.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(compendium['ENSG00000000003.14'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template experiment\n",
    "print(template_data.shape)\n",
    "template_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(template_data['ENSG00000000003.14'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual select one simulated experiment\n",
    "simulated_file_1 = os.path.join(\n",
    "    local_dir,\n",
    "    \"pseudo_experiment\",\n",
    "    \"selected_simulated_data_\"+project_id+\"_0.txt\")\n",
    "\n",
    "# Read data\n",
    "simulated_test_1 = pd.read_csv(\n",
    "    simulated_file_1,\n",
    "    header=0,\n",
    "    sep='\\t',\n",
    "    index_col=0)\n",
    "\n",
    "print(simulated_test_1.shape)\n",
    "simulated_test_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(simulated_test_1['ENSG00000000003.14'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual select another simulated experiment\n",
    "simulated_file_2 = os.path.join(\n",
    "    local_dir,\n",
    "    \"pseudo_experiment\",\n",
    "    \"selected_simulated_data_\"+project_id+\"_10.txt\")\n",
    "\n",
    "# Read data\n",
    "simulated_test_2 = pd.read_csv(\n",
    "    simulated_file_2,\n",
    "    header=0,\n",
    "    sep='\\t',\n",
    "    index_col=0)\n",
    "\n",
    "print(simulated_test_2.shape)\n",
    "simulated_test_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(simulated_test_2['ENSG00000000003.14'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check clustering of simulated samples**\n",
    "\n",
    "Check UMAP of original experiment and simulated experiments. Expect to see a similar structure in the template and simulated experiments. Also expect to see that the simulated experiment follows the distribution of the compendium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization in latent space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VAE models\n",
    "model_encoder_file = glob.glob(os.path.join(\n",
    "        NN_dir,\n",
    "        \"*_encoder_model.h5\"))[0]\n",
    "\n",
    "weights_encoder_file = glob.glob(os.path.join(\n",
    "    NN_dir,\n",
    "    \"*_encoder_weights.h5\"))[0]\n",
    "\n",
    "model_decoder_file = glob.glob(os.path.join(\n",
    "    NN_dir,\n",
    "    \"*_decoder_model.h5\"))[0]\n",
    "\n",
    "weights_decoder_file = glob.glob(os.path.join(\n",
    "    NN_dir,\n",
    "    \"*_decoder_weights.h5\"))[0]\n",
    "\n",
    "# Load saved models\n",
    "loaded_model = load_model(model_encoder_file)\n",
    "loaded_decode_model = load_model(model_decoder_file)\n",
    "\n",
    "loaded_model.load_weights(weights_encoder_file)\n",
    "loaded_decode_model.load_weights(weights_decoder_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding of real compendium (encoded)\n",
    "\n",
    "# Scale compendium\n",
    "compendium_scaled = scaler.transform(compendium)\n",
    "compendium_scaled_df = pd.DataFrame(compendium_scaled,\n",
    "                                    columns=compendium.columns,\n",
    "                                    index=compendium.index)\n",
    "\n",
    "# Encode compendium into latent space\n",
    "compendium_encoded = loaded_model.predict_on_batch(compendium_scaled_df)\n",
    "\n",
    "compendium_encoded_df = pd.DataFrame(data=compendium_encoded, \n",
    "                                     index=compendium.index)\n",
    "\n",
    "# Get and save model\n",
    "#model = umap.UMAP(random_state=randomState).fit(compendium_encoded_df)\n",
    "model = pca.fit(compendium_encoded_df)\n",
    "\n",
    "compendium_UMAPencoded = model.transform(compendium_encoded_df)\n",
    "\n",
    "compendium_UMAPencoded_df = pd.DataFrame(data=compendium_UMAPencoded,\n",
    "                                         index=compendium_encoded_df.index,\n",
    "                                         columns=['1','2'])\n",
    "\n",
    "# Add label\n",
    "compendium_UMAPencoded_df['experiment_id'] = 'background'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding of real template experiment (encoded)\n",
    "\n",
    "# Scale template data\n",
    "template_data_scaled = scaler.transform(template_data)\n",
    "template_data_scaled_df = pd.DataFrame(template_data_scaled,\n",
    "                                    columns=template_data.columns,\n",
    "                                    index=template_data.index)\n",
    "\n",
    "# Encode template experiment into latent space\n",
    "template_encoded = loaded_model.predict_on_batch(template_data_scaled)\n",
    "template_encoded_df = pd.DataFrame(data=template_encoded,\n",
    "                                   index=template_data.index)\n",
    "\n",
    "template_UMAPencoded = model.transform(template_encoded_df)\n",
    "\n",
    "template_UMAPencoded_df = pd.DataFrame(data=template_UMAPencoded,\n",
    "                                         index=template_encoded_df.index,\n",
    "                                         columns=['1','2'])\n",
    "\n",
    "# Add back label column\n",
    "template_UMAPencoded_df['experiment_id'] = 'template_experiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding of simulated experiment (encoded)\n",
    "\n",
    "# Scale simulated data\n",
    "simulated_test_2_scaled = scaler.transform(simulated_test_2)\n",
    "simulated_test_2_scaled_df = pd.DataFrame(simulated_test_2_scaled,\n",
    "                                          columns=simulated_test_2.columns,\n",
    "                                          index=simulated_test_2.index)\n",
    "\n",
    "# Encode simulated experiment into latent space\n",
    "simulated_encoded = loaded_model.predict_on_batch(simulated_test_2_scaled)\n",
    "simulated_encoded_df = pd.DataFrame(\n",
    "    simulated_encoded, index=simulated_test_2.index)\n",
    "\n",
    "simulated_UMAPencoded = model.transform(simulated_encoded_df)\n",
    "\n",
    "simulated_UMAPencoded_df = pd.DataFrame(data=simulated_UMAPencoded,\n",
    "                                         index=simulated_encoded_df.index,\n",
    "                                         columns=['1','2'])\n",
    "\n",
    "# Add back label column\n",
    "simulated_UMAPencoded_df['experiment_id'] = 'simulated_experiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes\n",
    "combined_UMAPencoded_df = pd.concat([compendium_UMAPencoded_df, \n",
    "                                    template_UMAPencoded_df,\n",
    "                                    simulated_UMAPencoded_df])\n",
    "\n",
    "combined_UMAPencoded_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = ggplot(combined_UMAPencoded_df, aes(x='1', y='2'))\n",
    "fig += geom_point(aes(color='experiment_id'), alpha=0.2)\n",
    "fig += labs(x ='PCA 1',\n",
    "            y = 'PCA 2',\n",
    "            title = 'PCA original data with experiments (latent space)')\n",
    "fig += theme_bw()\n",
    "fig += theme(\n",
    "    legend_title_align = \"center\",\n",
    "    plot_background=element_rect(fill='white'),\n",
    "    legend_key=element_rect(fill='white', colour='white'), \n",
    "    legend_title=element_text(family='sans-serif', size=15),\n",
    "    legend_text=element_text(family='sans-serif', size=12),\n",
    "    plot_title=element_text(family='sans-serif', size=15),\n",
    "    axis_text=element_text(family='sans-serif', size=12),\n",
    "    axis_title=element_text(family='sans-serif', size=15)\n",
    "    )\n",
    "fig += guides(colour=guide_legend(override_aes={'alpha': 1}))\n",
    "fig += scale_color_manual(['#bdbdbd', 'red', 'blue'])\n",
    "fig += geom_point(data=combined_UMAPencoded_df[combined_UMAPencoded_df['experiment_id'] == 'template_experiment'],\n",
    "                  alpha=0.2, \n",
    "                  color='blue')\n",
    "fig += geom_point(data=combined_UMAPencoded_df[combined_UMAPencoded_df['experiment_id'] == 'simulated_experiment'],\n",
    "                  alpha=0.1, \n",
    "                  color='red')\n",
    "\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization in gene space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding of real compendium\n",
    "\n",
    "# Get and save model\n",
    "model = umap.UMAP(random_state=randomState).fit(compendium_scaled_df)\n",
    "\n",
    "compendium_UMAPencoded = model.transform(compendium_scaled_df)\n",
    "\n",
    "compendium_UMAPencoded_df = pd.DataFrame(data=compendium_UMAPencoded,\n",
    "                                         index=compendium_scaled_df.index,\n",
    "                                         columns=['1','2'])\n",
    "# Add label\n",
    "compendium_UMAPencoded_df['experiment_id'] = 'background'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding of real template experiment\n",
    "\n",
    "template_UMAPencoded = model.transform(template_data_scaled_df)\n",
    "\n",
    "template_UMAPencoded_df = pd.DataFrame(data=template_UMAPencoded,\n",
    "                                         index=template_data_scaled_df.index,\n",
    "                                         columns=['1','2'])\n",
    "\n",
    "# Add back label column\n",
    "template_UMAPencoded_df['experiment_id'] = 'template_experiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding of simulated template experiment\n",
    "\n",
    "simulated_UMAPencoded = model.transform(simulated_test_2_scaled_df)\n",
    "\n",
    "simulated_UMAPencoded_df = pd.DataFrame(data=simulated_UMAPencoded,\n",
    "                                         index=simulated_test_2_scaled_df.index,\n",
    "                                         columns=['1','2'])\n",
    "\n",
    "# Add back label column\n",
    "simulated_UMAPencoded_df['experiment_id'] = 'simulated_experiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes\n",
    "combined_UMAPencoded_df = pd.concat([compendium_UMAPencoded_df, \n",
    "                                    template_UMAPencoded_df,\n",
    "                                    simulated_UMAPencoded_df])\n",
    "\n",
    "combined_UMAPencoded_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = ggplot(combined_UMAPencoded_df, aes(x='1', y='2'))\n",
    "fig += geom_point(aes(color='experiment_id'), alpha=0.2)\n",
    "fig += labs(x ='UMAP 1',\n",
    "            y = 'UMAP 2',\n",
    "            title = 'UMAP original data with experiments (gene space)')\n",
    "fig += theme_bw()\n",
    "fig += theme(\n",
    "    legend_title_align = \"center\",\n",
    "    plot_background=element_rect(fill='white'),\n",
    "    legend_key=element_rect(fill='white', colour='white'), \n",
    "    legend_title=element_text(family='sans-serif', size=15),\n",
    "    legend_text=element_text(family='sans-serif', size=12),\n",
    "    plot_title=element_text(family='sans-serif', size=15),\n",
    "    axis_text=element_text(family='sans-serif', size=12),\n",
    "    axis_title=element_text(family='sans-serif', size=15)\n",
    "    )\n",
    "fig += guides(colour=guide_legend(override_aes={'alpha': 1}))\n",
    "fig += scale_color_manual(['#bdbdbd', 'red', 'blue'])\n",
    "fig += geom_point(data=combined_UMAPencoded_df[combined_UMAPencoded_df['experiment_id'] == 'template_experiment'],\n",
    "                  alpha=0.2, \n",
    "                  color='blue')\n",
    "fig += geom_point(data=combined_UMAPencoded_df[combined_UMAPencoded_df['experiment_id'] == 'simulated_experiment'],\n",
    "                  alpha=0.2, \n",
    "                  color='red')\n",
    "\n",
    "print(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ranked_pathways] *",
   "language": "python",
   "name": "conda-env-ranked_pathways-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
